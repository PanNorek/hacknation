# HackNation - System Prognozowania Geopolitycznego

System analizy geopolitycznej wykorzystujƒÖcy Mesa framework i Google Gemini AI do generowania wyja≈õnialnych prognoz dla kraj√≥w.

## üöÄ Szybki Start

### 1. Instalacja zale≈ºno≈õci

```bash
uv sync
```

### 2. Konfiguracja

Skopiuj przyk≈Çadowy plik konfiguracyjny:

```bash
cp .env.example .env
```

Edytuj `.env` i dodaj sw√≥j klucz API Google:

```env
GEMINI_API_KEY=your_api_key_here
```

**Test konfiguracji:**

```bash
python3 test_config.py
```

### 3. Uruchomienie

```bash
python3 test2.py
```

üìñ **Szczeg√≥≈Çowy przewodnik**: Zobacz [QUICKSTART.md](QUICKSTART.md) dla zaawansowanych opcji konfiguracji.

## ü§ñ Automatyczna Aktualizacja Danych

System automatycznie aktualizuje dane kraj√≥w:

- **Harmonogram**: Codziennie o 3:00 UTC
- **≈πr√≥d≈Ça**: Oficjalne strony rzƒÖdowe
- **Technologia**: GitHub Actions + LLM

### Rƒôczne uruchomienie:

```bash
# Przez GitHub Web UI
# Actions ‚Üí "Update Germany Data" ‚Üí Run workflow

# Przez GitHub CLI
gh workflow run "Update Germany Data"

# Aktualizacja wielu kraj√≥w
gh workflow run "Update All Countries Data" -f countries="germany,france"
```

üìñ **Wiƒôcej informacji**: [ON_DEMAND_ACTIONS.md](ON_DEMAND_ACTIONS.md) - Kompletny przewodnik

## ‚öôÔ∏è Konfiguracja

System u≈ºywa pliku `.env` do konfiguracji wszystkich parametr√≥w. Zobacz [CONFIG.md](CONFIG.md) dla szczeg√≥≈Çowych informacji.

### G≈Ç√≥wne parametry:

- **GEMINI_MODEL_NAME**: Model AI (domy≈õlnie: `gemini-2.0-flash`)
- **GEMINI_TEMPERATURE**: Kreatywno≈õƒá odpowiedzi (domy≈õlnie: `0.2`)
- **GEMINI_MAX_TOKENS**: Maksymalna d≈Çugo≈õƒá odpowiedzi (domy≈õlnie: `4096`)
- **LOG_LEVEL**: Szczeg√≥≈Çowo≈õƒá log√≥w (domy≈õlnie: `INFO`)
- **REPORT_DIR**: Katalog dla raport√≥w PDF (domy≈õlnie: `reports`)

Zobacz pe≈ÇnƒÖ dokumentacjƒô w [CONFIG.md](CONFIG.md).

## üìä Funkcje

- **Multi-czynnikowa analiza scenariuszy**: 6 wsp√≥≈Çzale≈ºnych czynnik√≥w globalnych z wagami
- **Chain of Thought**: Pe≈Çna wyja≈õnialno≈õƒá procesu analizy AI
- **Prognozy 12 i 36-miesiƒôczne**: Pozytywne i negatywne scenariusze
- **Raporty PDF**: Profesjonalne raporty z analizami
- **System logowania**: Szczeg√≥≈Çowe logi w plikach i konsoli
- **Web Scraping**: Automatyczne zbieranie danych o krajach z wiarygodnych ≈∫r√≥de≈Ç

## üï∑Ô∏è Zbieranie Danych o Krajach

System umo≈ºliwia automatyczne zbieranie danych z oficjalnych ≈∫r√≥de≈Ç:

```bash
# Scrape danych dla pojedynczego kraju
python3 scrape_country_data.py germany

# Scrape wszystkich kraj√≥w
python3 scrape_country_data.py --all
```

Zobacz [SCRAPER_GUIDE.md](SCRAPER_GUIDE.md) dla szczeg√≥≈Ç√≥w.

## üìÅ Struktura Projektu

```
hacknation/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agents/              # Agenci Mesa
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ country_agent.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ forecasting_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ configuration.py     # System konfiguracji
‚îÇ   ‚îî‚îÄ‚îÄ report_generator.py  # Generator PDF
‚îú‚îÄ‚îÄ resources/               # Dane kraj√≥w (JSON)
‚îú‚îÄ‚îÄ logs/                    # Pliki log√≥w
‚îú‚îÄ‚îÄ reports/                 # Raporty PDF
‚îú‚îÄ‚îÄ test2.py                 # G≈Ç√≥wny skrypt
‚îî‚îÄ‚îÄ .env                     # Konfiguracja (nie w git)
```

## üìñ Dokumentacja

- [CONFIG.md](CONFIG.md) - Szczeg√≥≈Çy konfiguracji
- [CHAIN_OF_THOUGHT.md](CHAIN_OF_THOUGHT.md) - Wyja≈õnialno≈õƒá AI
- [SCENARIO.md](SCENARIO.md) - Dokumentacja scenariuszy
- [WIELOCZYNNIKOWA_ANALIZA.md](WIELOCZYNNIKOWA_ANALIZA.md) - Analiza wieloczynnikowa

## üõ†Ô∏è Technologie

- **Mesa**: Framework do symulacji opartych na agentach
- **Google Gemini AI**: Generowanie prognoz
- **Pydantic**: Walidacja danych i konfiguracji
- **ReportLab**: Generowanie raport√≥w PDF
- **Python 3.13+**

## üìù Licencja

MIT
# HackNation AI Agent API

A FastAPI application that provides access to a Gemini AI agent for querying country information about Atlantis.

## Features

- **Gemini AI Agent**: Powered by Google's Gemini models
- **Country Data**: Pre-loaded with comprehensive Atlantis country information
- **Vector Database**: PostgreSQL with pgvector for similarity search
- **RESTful API**: Clean endpoints for agent interaction
- **Structured Logging**: Comprehensive logging configuration with startup/shutdown events
- **Pydantic Models**: Type-safe request/response handling
- **Configurable**: Extensive configuration via environment variables

## Database Setup

The project uses PostgreSQL with pgvector extension for vector similarity search.

### Using Docker Compose (Recommended)

```bash
# Start PostgreSQL with pgvector
docker-compose up -d

# Check if database is ready
docker-compose logs postgres

# Run database tests
python src/db/test.py
```

### Manual Docker Build

```bash
# Build PostgreSQL container with pgvector and auto-migrations
docker build -f src/db/Dockerfile -t hacknation-postgres .

# Run container (migrations run automatically during database initialization)
docker run -d \
  --name hacknation-postgres \
  -p 5432:5432 \
  -e POSTGRES_DB=hacknation \
  -e POSTGRES_USER=hacknation_user \
  -e POSTGRES_PASSWORD=hacknation_password \
  hacknation-postgres

# Check logs to see migration progress (runs during first startup)
docker logs hacknation-postgres

# Container runs PostgreSQL normally after migrations complete
```

### Database Configuration

Create a `.env` file with database settings:

```env
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=hacknation
DB_USER=hacknation_user
DB_PASSWORD=hacknation_password

# ... other settings ...
```

### Database Schema & Models

The database includes three main tables with vector columns and corresponding SQLAlchemy models:

#### Tables & Models
- **`embeddings`** ‚Üí `Embedding` model: General text embeddings (384-dim vectors)
- **`instructions`** ‚Üí `Instruction` model: User instructions with embeddings
- **`country_data`** ‚Üí `CountryData` model: Atlantis country information with embeddings

#### Features
- **Vector similarity search** enabled with IVFFlat indexes for fast queries
- **JSONB metadata** storage for flexible data
- **Automatic timestamps** with timezone support
- **Cosine similarity functions** for vector operations

#### Usage Examples

```python
from src.db import EmbeddingRepository, create_embedding, find_similar_embeddings

# Create and store an embedding
embedding = create_embedding(
    content="Example text",
    embedding=[0.1, 0.2, ...],  # 384-dim vector
    metadata={"source": "example"}
)

# Find similar content
similar = find_similar_embeddings(query_embedding, limit=5, threshold=0.8)

# Work with Atlantis data
atlantis = get_atlantis_data()
print(f"Population: {atlantis.population}")
```

### Database Migrations with Alembic

The project includes Alembic for database schema migrations:

```bash
# Initialize database (if not already done)
make db-init

# Create a new migration
make db-migrate msg="add new table"

# Apply migrations
make db-upgrade

# View migration history
make db-history

# Check current migration status
make db-current
```

### Alembic Commands

```bash
# Create new migration file
alembic revision -m "description"

# Auto-generate migration from model changes
alembic revision --autogenerate -m "auto update"

# Apply all migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# View migration status
alembic current
```

## Quick Start

```bash
# Install dependencies
uv sync

# Start database
docker-compose up -d

# Run the API
make run-api
# or
uv run uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at http://localhost:8000 with automatic logging of all requests and application events.

## API Endpoints

### GET /
Basic API information and available endpoints.

### POST /prompt
Send prompts to the Gemini AI agent.

**Request Body**:
```json
{
  "prompt": "What is the population of Atlantis?",
  "context": {"additional": "data"}
}
```

### GET /agent_info
Get information about the Gemini AI agent.

### POST /instructions
Save user instructions.

**Request Body**:
```json
{
  "instructions": "Custom instructions for the AI agent"
}
```

### GET /country_data
Get the Atlantis country data used by the agent.

## Testing

You can test the API using curl:

```bash
# Test the root endpoint
curl http://localhost:8000/

# Test agent info
curl http://localhost:8000/agent_info

# Test prompting
curl -X POST http://localhost:8000/prompt \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What is Atlantis known for economically?"}'
```

Or use the interactive API documentation at: http://localhost:8000/docs

## Database Testing

Run the database tests to verify vector operations:

```bash
# Test database connection and vector operations
python src/db/test.py
```

This will test:
- Database connectivity
- Vector operations
- Embedding storage and retrieval
- Similarity search functionality
